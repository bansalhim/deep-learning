{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdLbUEQtfqXv+8hGxm5TZi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bansalhim/Deep-learning-assignment/blob/main/Assignment3_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression as a Soft Decision**"
      ],
      "metadata": {
        "id": "0AqQy_2IQ839"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#load daataset\n",
        "df=pd.read_csv('/content/glass.csv')\n",
        "# Inspect the dataset\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "df.head()# now getting values in daataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "pEt_HT5LRBbl",
        "outputId": "91a391bc-35e7-4b55-b4e5-d05c650a1444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (214, 10)\n",
            "Columns: ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
              "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
              "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
              "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
              "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
              "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-306c8e68-4443-47ee-bcb6-26ec00e8e9b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-306c8e68-4443-47ee-bcb6-26ec00e8e9b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-306c8e68-4443-47ee-bcb6-26ec00e8e9b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-306c8e68-4443-47ee-bcb6-26ec00e8e9b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 214,\n  \"fields\": [\n    {\n      \"column\": \"RI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0030368637393854334,\n        \"min\": 1.51115,\n        \"max\": 1.53393,\n        \"num_unique_values\": 178,\n        \"samples\": [\n          1.51966,\n          1.51808,\n          1.51969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Na\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8166035557149829,\n        \"min\": 10.73,\n        \"max\": 17.38,\n        \"num_unique_values\": 142,\n        \"samples\": [\n          14.38,\n          13.02,\n          13.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4424078448704414,\n        \"min\": 0.0,\n        \"max\": 4.49,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          3.86,\n          3.47,\n          2.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Al\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49926964560048454,\n        \"min\": 0.29,\n        \"max\": 3.5,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          1.48,\n          1.65,\n          1.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Si\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7745457947651124,\n        \"min\": 69.81,\n        \"max\": 75.41,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          72.22,\n          73.06,\n          71.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6521918455589802,\n        \"min\": 0.0,\n        \"max\": 6.21,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.47,\n          0.31,\n          0.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4231534872813945,\n        \"min\": 5.43,\n        \"max\": 16.19,\n        \"num_unique_values\": 143,\n        \"samples\": [\n          12.5,\n          8.52,\n          11.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ba\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4972192605997036,\n        \"min\": 0.0,\n        \"max\": 3.15,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          0.64,\n          0.61,\n          1.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09743870063650086,\n        \"min\": 0.0,\n        \"max\": 0.51,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.51,\n          0.03,\n          0.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Inspecting Data\n",
        "\n",
        "# The output column we want to predict is 'Type'.\n",
        "# All other columns are numeric values of chemical components.\n",
        "\n",
        "print(\"Data types:\\n\", df.dtypes)# printiig datatype which is floating values in dataset\n",
        "print(\"\\nSummary statistics:\\n\", df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuYf7vt2R2yw",
        "outputId": "8ed18984-b4c1-499c-8b20-35369e3c7be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types:\n",
            " RI      float64\n",
            "Na      float64\n",
            "Mg      float64\n",
            "Al      float64\n",
            "Si      float64\n",
            "K       float64\n",
            "Ca      float64\n",
            "Ba      float64\n",
            "Fe      float64\n",
            "Type      int64\n",
            "dtype: object\n",
            "\n",
            "Summary statistics:\n",
            "                RI          Na          Mg          Al          Si           K  \\\n",
            "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
            "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
            "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
            "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
            "25%      1.516522   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
            "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
            "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
            "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
            "\n",
            "               Ca          Ba          Fe        Type  \n",
            "count  214.000000  214.000000  214.000000  214.000000  \n",
            "mean     8.956963    0.175047    0.057009    2.780374  \n",
            "std      1.423153    0.497219    0.097439    2.103739  \n",
            "min      5.430000    0.000000    0.000000    1.000000  \n",
            "25%      8.240000    0.000000    0.000000    1.000000  \n",
            "50%      8.600000    0.000000    0.000000    2.000000  \n",
            "75%      9.172500    0.000000    0.100000    3.000000  \n",
            "max     16.190000    3.150000    0.510000    7.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Binary classification setup\n",
        "# Convert 'Type' into a binary target variable: as type is output so type is given 1 and rest are given 0 value\n",
        "# Type 1 -> positive class (1)\n",
        "# All other types -> negative class (0)\n",
        "\n",
        "df[\"y\"] = (df[\"Type\"] == 1).astype(int)\n",
        "\n",
        "# Drop the original Type column\n",
        "df = df.drop(columns=[\"Type\"])\n",
        "\n",
        "# Verify\n",
        "df.head()\n",
        "#Why this is done\n",
        "#because Logistic regression handles binary output only."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "k9-8rUcLSbE1",
        "outputId": "862722dc-020c-4499-84f9-0b3a33f31357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  y\n",
              "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0  1\n",
              "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0  1\n",
              "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0  1\n",
              "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0  1\n",
              "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7044c558-2d69-4e16-a5b3-4027658546fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7044c558-2d69-4e16-a5b3-4027658546fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7044c558-2d69-4e16-a5b3-4027658546fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7044c558-2d69-4e16-a5b3-4027658546fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#because Logistic regression handles binary output only\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"RI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018009525257485005,\n        \"min\": 1.51618,\n        \"max\": 1.52101,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.51761,\n          1.51742,\n          1.51618\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Na\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2780647406630335,\n        \"min\": 13.21,\n        \"max\": 13.89,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          13.89,\n          13.27,\n          13.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39452503089157737,\n        \"min\": 3.55,\n        \"max\": 4.49,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.6,\n          3.62,\n          3.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Al\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.161802348561447,\n        \"min\": 1.1,\n        \"max\": 1.54,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.36,\n          1.24,\n          1.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Si\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5159166599364654,\n        \"min\": 71.78,\n        \"max\": 73.08,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          72.73,\n          73.08,\n          72.99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2079663434308542,\n        \"min\": 0.06,\n        \"max\": 0.57,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.48,\n          0.55,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3900640972968417,\n        \"min\": 7.78,\n        \"max\": 8.75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.83,\n          8.07,\n          7.78\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ba\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Split into features and label\n",
        "# means from this i get is now we are spliting of seprating input which is x and output which is y\n",
        "X = df.drop(columns=[\"y\"]).values\n",
        "y = df[\"y\"].values\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "#i observe that the model learns a mapping from inputs X to output y."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH3vuNdjTANw",
        "outputId": "465ec4e0-4668-44c6-df46-f2f7e786c1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (214, 9)\n",
            "y shape: (214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Split into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Testing samples:\", X_test.shape[0])\n",
        "# so total we have 214 so it split into training nad testing 171  for training and 43 for testing\n",
        "# as test size is 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF2GhUDZTSB5",
        "outputId": "628fa94d-b77e-4dc5-98c4-e9ec43ffa65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 171\n",
            "Testing samples: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Scaling ensures all features have zero mean and unit variance.\n",
        "# Without scaling, features with larger numeric ranges dominate training.\n",
        "# so we do not want that for that scaling is performed\n",
        "# so mean is 0 and sd is 1 .Scaling ensures all features are equal in importance."
      ],
      "metadata": {
        "id": "VO_eMblJT-l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Define Sigmoid\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"Compute sigmoid activation.\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "## Now i use sigmoid function becauseit gives a smooth probability between 0 and 1.\n",
        "# and for complex data having noice sigmoid is used"
      ],
      "metadata": {
        "id": "oRRT_-ZWURh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Compute predicted probabilities-\n",
        "def predict_proba(X, w, b):\n",
        "    z = X @ w + b#equation is used in this\n",
        "    p = sigmoid(z)\n",
        "    return p\n"
      ],
      "metadata": {
        "id": "HqYJAoPKUq8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Define loss function\n",
        "\n",
        "def loss(y, p):\n",
        "    \"\"\"Binary cross-entropy loss.\"\"\"\n",
        "    return -np.mean(y * np.log(p + 1e-8) + (1 - y) * np.log(1 - p + 1e-8))\n",
        "#so large penalty for confident wrong predictions. as logistic tell how correct confidence is and if confidence is wrong so large penatly is made and Cross-entropy measures how wrong the predicted probabilities are."
      ],
      "metadata": {
        "id": "INN1dqZOU_SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Weight update rule->Gradient Descent\n",
        "def update_weights(X, y, w, b, lr):\n",
        "    p = predict_proba(X, w, b)\n",
        "    error = p - y\n",
        "    w = w - lr * (X.T @ error) / len(y)\n",
        "    b = b - lr * np.mean(error)\n",
        "    return w, b\n",
        "##  error (p - y) indicates both direction and magnitude of correction\n",
        "# llearning rate controls how fast we adjust weights.\n",
        "#This is the learning step — it reduces the loss step-by-step."
      ],
      "metadata": {
        "id": "S-4dvZzwVfkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Training loop\n",
        "w = np.zeros(X_train.shape[1])\n",
        "b = 0.0\n",
        "lr = 0.1\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    p_train = predict_proba(X_train, w, b)\n",
        "    w, b = update_weights(X_train, y_train, w, b, lr)\n",
        "    if epoch % 10 == 0:\n",
        "        current_loss = loss(y_train, p_train)\n",
        "        print(f\"Epoch {epoch:3d}, Loss: {current_loss:.6f}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# loss should decrease with epochs\n",
        "# If it increases it meansthat learning rate too high or gradient incorrect.\n",
        "#This runs training many times (100 epochs).\n",
        "#Each round will predict then calculate loss and then update weights."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJmltljeV67-",
        "outputId": "0b113592-72f2-4a80-9bb9-d638025acd15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0, Loss: 0.693147\n",
            "Epoch  10, Loss: 0.615693\n",
            "Epoch  20, Loss: 0.577566\n",
            "Epoch  30, Loss: 0.554707\n",
            "Epoch  40, Loss: 0.539208\n",
            "Epoch  50, Loss: 0.527877\n",
            "Epoch  60, Loss: 0.519169\n",
            "Epoch  70, Loss: 0.512233\n",
            "Epoch  80, Loss: 0.506557\n",
            "Epoch  90, Loss: 0.501812\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Convert probabilities to class labels\n",
        "def predict_label(p, threshold=0.5):\n",
        "    return (p >= threshold).astype(int)\n",
        "\n",
        "# Evaluate on test data\n",
        "p_test = predict_proba(X_test, w, b)\n",
        "y_pred_05 = predict_label(p_test, 0.5)\n",
        "y_pred_07 = predict_label(p_test, 0.7)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"Accuracy (threshold 0.5):\", accuracy_score(y_test, y_pred_05))\n",
        "print(\"Accuracy (threshold 0.7):\", accuracy_score(y_test, y_pred_07))\n",
        "print(\"Confusion matrix (0.5):\\n\", confusion_matrix(y_test, y_pred_05))\n",
        "# Higher threshold (0.7) reduces false positives but may increase false negatives.\n",
        "# In quality control, it's safer to label uncertain samples as \"not Type 1.\"\n",
        "#If the model is >50% confident → classify as Type 1.\n",
        "#we can change threshold to make it stricter or looser."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPJFTxmCWJzP",
        "outputId": "5313e0db-e5ee-4df5-a7e6-15648e758d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (threshold 0.5): 0.8604651162790697\n",
            "Accuracy (threshold 0.7): 0.7209302325581395\n",
            "Confusion matrix (0.5):\n",
            " [[30  2]\n",
            " [ 4  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The model achieved higher accuracy at threshold 0.5 (86%) than at 0.7 (72%).\n",
        "# icreasing the threshold makes the model more conservative in predicting \"Type 1.\"\n",
        "# As a result, it predicts fewr positives (reduces false positives) but misses some actual positives (increases false negatives).\n",
        "# This is expected behavior — a higher threshold increases precision but decreases recall.\n",
        "# In a real-world qulity control setting, such as identifying a rare glass type,\n",
        "# we may prefer a higher threshold to redue false alarms, even at the cost of missing some positive.\n"
      ],
      "metadata": {
        "id": "DQgbWdxOcCgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Precision (0.5):\", precision_score(y_test, y_pred_05))\n",
        "print(\"Recall (0.5):\", recall_score(y_test, y_pred_05))\n",
        "print(\"Precision (0.7):\", precision_score(y_test, y_pred_07))\n",
        "print(\"Recall (0.7):\", recall_score(y_test, y_pred_07))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkVGZDyGcXI7",
        "outputId": "f39cb0eb-3f01-4147-aab2-d9eb602ef910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (0.5): 0.7777777777777778\n",
            "Recall (0.5): 0.6363636363636364\n",
            "Precision (0.7): 0.0\n",
            "Recall (0.7): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# At threshold = 0.5, the model predicts some positive (Type 1) samples correctly,\n",
        "# giving decent precision (0.78) and recall (0.64).\n",
        "# When threshold increases to 0.7, the model becomes too strict —\n",
        "# no sample reaches 0.7 probability, so it predicts all as \"Not Type 1\".\n",
        "# Therefore, both precision and recall drop to 0.\n",
        "# This shows how threshold tuning controls the trade-off:\n",
        "# lower threshold → more positives (higher recall),\n",
        "# higher threshold → fewer positives (higher precision, but only if any positives remain).\n",
        "# In our case, threshold 0.7 is too high for this dataset.\n"
      ],
      "metadata": {
        "id": "bnVGyfHzcgiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Example probability inspection\n",
        "sample_probs = p_test[:10]\n",
        "print(\"Sample predicted probabilities:\\n\", sample_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vyihudoWhr0",
        "outputId": "9e0992d1-c01b-4a22-ac50-bbaae7b3ce30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample predicted probabilities:\n",
            " [0.46596617 0.02699184 0.60769832 0.02225283 0.30880036 0.30065433\n",
            " 0.5507444  0.44201251 0.43843704 0.40641316]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14 –\n",
        "\n",
        "**1. How this differs from a perceptron?**\n",
        "\n",
        "The perceptron outputs a hard 0/1 decision using a step function.\n",
        "Logistic regression give outputs a continuous probability using the sigmoid function.\n",
        "This allows it to represent uncertainty and to train using gradient-based optimization.and also if we have noisy data logistic handles more better then perceptron.\n",
        "\n",
        "**2. Why the sigmoid matters?**\n",
        "\n",
        "The sigmoid converts the linear combination of inputs (evidence z) into a bounded value between 0 and 1.\n",
        "This makes the output interpretable as probability and keeps the gradient smooth and differentiable for learning instead of getting hard binary values.\n",
        "\n",
        "3. What problem still remains unsolved?\n",
        "\n",
        "Even though the model learns probabilities, it still assumes a linear boundary between classes.\n",
        "It cannot capture complex or nonlinear relationships — something that later neural networks with multiple layers and nonlinear activations will address."
      ],
      "metadata": {
        "id": "kXpXR6IpWrQl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgkN8AacXvVT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}